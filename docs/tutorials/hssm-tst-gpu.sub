#!/usr/bin/env bash
#SBATCH -J hssm_gpu
#SBATCH -A bornstea_lab_gpu
#SBATCH -p gpu
#SBATCH --gres=gpu:V100:1
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=16G
#SBATCH --time=4-00:00:00
#SBATCH --array=0-2
#SBATCH -o logs/hssm_gpu_%A_%a.out   # unique stdout per array task
#SBATCH -e logs/hssm_gpu_%A_%a.err   # unique stderr per array task
#SBATCH --mail-type=end
#SBATCH --mail-user=jungsuy@uci.edu
set -euo pipefail

CHAIN_ID="${SLURM_ARRAY_TASK_ID}"
SSC="${1}"

PY="/data/homezvol1/jungsuy/conda-envs/hssm-gpu/bin/python"

unset XLA_FLAGS
export PYTHONNOUSERSITE=1
export JAX_ENABLE_X64=0            # disable x64 to keep fp32 everywhere
export XLA_PYTHON_CLIENT_MEM_FRACTION=.90

nvidia-smi || true
"$PY" - <<'PY'
import jax
print("JAX devices:", jax.devices(), "backend:", jax.default_backend())
PY

srun -u "$PY" /pub/jungsuy/HSSM/docs/tutorials/hssm-tst-gpu.py \
  --ssc "${SSC}" \
  --chain-id "${CHAIN_ID}" \
  --draws 5000 \
  --tune 5000 \
  --sampler nuts_numpyro \
  --chains 1                 # ensure one chain per job
echo "Done @ $(date)"